{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lunch_predictor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KKw-C41HXm3t",
        "outputId": "ac28d7f5-500b-4016-91f0-6a1519f050f9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "filename = \"/StudentsPerformance.csv\"\n",
        "\n",
        "def get_path(filename):\n",
        "    \n",
        "    my_dir = os.getcwd()\n",
        "    file_path = my_dir + filename\n",
        "    return file_path\n",
        "\n",
        "path = get_path(filename)\n",
        "data = pd.read_csv(path)\n",
        "data.shape\n",
        "data.describe()\n",
        "\n",
        "#function used from a previous lab in 221 \n",
        "#StudentsPerformance.cvs used from Kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>math score</th>\n",
              "      <th>reading score</th>\n",
              "      <th>writing score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>66.08900</td>\n",
              "      <td>69.169000</td>\n",
              "      <td>68.054000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15.16308</td>\n",
              "      <td>14.600192</td>\n",
              "      <td>15.195657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>57.00000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>57.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>66.00000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>69.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>77.00000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>79.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.00000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       math score  reading score  writing score\n",
              "count  1000.00000    1000.000000    1000.000000\n",
              "mean     66.08900      69.169000      68.054000\n",
              "std      15.16308      14.600192      15.195657\n",
              "min       0.00000      17.000000      10.000000\n",
              "25%      57.00000      59.000000      57.750000\n",
              "50%      66.00000      70.000000      69.000000\n",
              "75%      77.00000      79.000000      79.000000\n",
              "max     100.00000     100.000000     100.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAxWw-FjbKPJ",
        "outputId": "e61aaa01-1b9e-4cc2-ddbe-0a6361177be2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqR_Q-FBYwwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebec5c6-8615-4d7e-ddb5-c8fecda5733c"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "X = data[['math score', 'reading score', 'writing score']]\n",
        "y = data['lunch']\n",
        "\n",
        "\n",
        "X_train , X_test , y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "\n",
        "svc = SVC(kernel = 'linear')\n",
        "\n",
        "\n",
        "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
        "\n",
        "\n",
        "\n",
        "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
        "param_grid = {\n",
        "    'svc__C': np.logspace(-6, 3, 12),\n",
        "    'svc__max_iter': [-3, -2, -1, 1],\n",
        "    'svc__tol' : np.logspace(-4, 4, 10) \n",
        "}\n",
        "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
        "\n",
        "print(search.best_params_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameter (CV score=0.720):\n",
            "{'svc__C': 0.5336699231206312, 'svc__max_iter': -1, 'svc__tol': 0.046415888336127774}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2a33ugag9KB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fc15ef-e5ed-4786-c9b5-2789e350ff31"
      },
      "source": [
        "\n",
        "svc = SVC(kernel = 'linear', C = 0.5336, tol = .0464)\n",
        "ss = StandardScaler()\n",
        "\n",
        "pipe = Pipeline([('scaler', ss), ('svc', svc)])\n",
        "\n",
        "model = svc.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "print(model.score(X_test, y_test))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.684\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "free/reduced       0.76      0.29      0.41        98\n",
            "    standard       0.67      0.94      0.78       152\n",
            "\n",
            "    accuracy                           0.68       250\n",
            "   macro avg       0.71      0.61      0.60       250\n",
            "weighted avg       0.70      0.68      0.64       250\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQvb55pz1kzk"
      },
      "source": [
        "#try log reg\n",
        "#try non linear kernel"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}